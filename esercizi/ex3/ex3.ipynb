{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ex3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiNAoRAQ+E5aUAA0bwuExc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erodola/NumMeth-s2-2023/blob/main/esercizi/ex3/ex3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benvenuti alla terza esercitazione di Metodi Numerici!\n",
        "\n",
        "Oggi vedremo il concetto di regolarizzazione (*sparsità* e *regolarità* (smoothness)) in modo pratico verificando l'effetto su segniali definiti su diversi domini. Importiamo i requirements, definiamo alcune funzioni di supporto e scarichiamo i dati necessari:"
      ],
      "metadata": {
        "id": "pxq-AoV8gKpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.sparse as sparse\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "0ImcPCfwgQ9W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(x, y, title=None):\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    ax = fig.add_subplot()\n",
        "    ax.set_xlabel('t')\n",
        "    ax.set_title(title)\n",
        "    ax.plot(x, y, '-')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mfd14RoGhozo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/erodola/NumMeth-s2-2023/raw/main/esercizi/ex3/drums.wav\n",
        "!wget https://github.com/erodola/NumMeth-s2-2023/raw/main/esercizi/ex3/mountain.png"
      ],
      "metadata": {
        "id": "MbEQWRHFlOyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Regolarizzazione di Tikhonov\n",
        "\n",
        "Riprendiamo il fitting di polinomi usando il metodo dei minimi quadrati. Supponiamo di trovarci nel caso in cui il numero di punti a disposizione è inferiore a quello del grado del polinomio. Per esempio se abbiamo $n=4$, il sistema è sotto-determinato nel caso in cui il numero di coppie di punti a nostra disposizione è inferiore a 5. "
      ],
      "metadata": {
        "id": "KbzVZroaEn4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "\n",
        "x2 = np.array([0, 1.])[:, np.newaxis]\n",
        "y2 = np.array([2., 6.])[:, np.newaxis]\n",
        "\n",
        "plt.scatter(x2, y2)"
      ],
      "metadata": {
        "id": "zScIXcCO_GlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proviamo a trovare una soluzione $\\theta$ usando il regolarizzatore di Tikhonov\n",
        "$ \\mathbf{\\theta} = (\\mathbf{X}^T \\mathbf{X} + \\alpha \\mathbf{I})^{-1} \\mathbf{X}^T \\mathbf{y}$. Per questo esempio scegliamo $\\alpha = 1$."
      ],
      "metadata": {
        "id": "Q3uEuKm0Jt6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = np.concatenate((x2**4, x2**3, x2**2, x2**1, x2**0),1)\n",
        "print(f\"X2 = {X2}\")\n",
        "\n",
        "alpha = 1.\n",
        "theta2 = np.linalg.inv(X2.T @ X2 + alpha * np.eye(5)) @ X2.T @ y2\n",
        "print(f\"theta = {theta2}\")"
      ],
      "metadata": {
        "id": "9bzSDlG4J3J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2_new = np.linspace(-2, 2, 20)[:, np.newaxis]\n",
        "X2_new = np.concatenate((x2_new**4, x2_new**3, x2_new**2, x2_new**1, x2_new**0),1)\n",
        "y2_new = X2_new@theta2  \n",
        "print(f\"y2_new = {y2_new}\")"
      ],
      "metadata": {
        "id": "EjSQn5z5L8zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x2_new, y2_new)\n",
        "plt.scatter(x2, y2, color='r')\n",
        "plt.legend(['Model', 'Data'])"
      ],
      "metadata": {
        "id": "wkO3CUmrNt2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Esercizio 1 - Alpha sweep**\n",
        "\n",
        " 1. Rifare l'esempio aggiungendo un data point. Confrontare la soluzione\n",
        " per lo stesso valore di $\\alpha = 1$\n",
        " 2. Provare a variare il valore di $\\alpha$ usando i valori [0.1, 0.5, 10., 100.]. Plottare le diverse curve fittate. Come cambiano le componenti di $\\theta$ all'aumentare di $\\alpha$ (calcolare la norma delle diverse $\\alpha$)? \n",
        " 3. BONUS: Cosa succede quando $\\alpha \\to 0$? Come si può interpretare in modo matematico questo fenomeno?"
      ],
      "metadata": {
        "id": "jUkNuReERhQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "alpha = 1.\n",
        "\n",
        "# SCRIVERE QUI SOTTO IL CODICE DELL'ESERCIZIO\n",
        "################\n",
        "\n",
        "# Aggiungiamo un punto a x\n",
        "\n",
        "x3 = ... \n",
        "y3 = ... \n",
        "\n",
        "\n",
        "# Creiamo la matrice dei dati X3\n",
        "X3 = ... \n",
        "\n",
        "# Applichiamo la formula della ridge regression\n",
        "theta3 = ... \n",
        "\n",
        "# Valutiamo il nuovo modello in alcuni punti\n",
        "x3_new = ...\n",
        "X3_new = ...\n",
        "y3_new = ... \n",
        "\n",
        "# Plottiamo il nuovo modello (e confrontiamo con il modello fittato con 2 punti)\n",
        "# plt.scatter(x2_new, y2_new)\n",
        "# plt.scatter(x2, y2, color='r')\n",
        "# plt.legend(['Model', 'Data'])\n",
        "# plt.xlim(-2, 2)\n",
        "# plt.ylim(-15, 15)\n",
        "# plt.title('Ridge regression n = 4 con 2 punti (alpha = 1)')\n",
        "\n",
        "# plt.figure()\n",
        "# plt.scatter(x3_new, y3_new)\n",
        "# plt.scatter(x3, y3, color='r')\n",
        "# plt.legend(['Model', 'Data'])\n",
        "# plt.xlim(-2, 2)\n",
        "# plt.ylim(-15, 15)\n",
        "# plt.title('Ridge regression n = 4 con 3 punti (alpha = 1)')\n",
        "\n",
        "# Effettuiamo la regressione regolarizzata per diversi valori di alpha\n",
        "for alpha_i in [0.1, 0.5, 10., 100.]:\n",
        "  theta = ... \n",
        "  # Stampiamo i valori di theta e la relativa norma\n",
        "  print(...)\n",
        "  print(...)\n",
        "  \n",
        "  # valutiamo il modello nei nuovi punti\n",
        "  y_new = ... \n",
        "    \n",
        "  # plt.figure()\n",
        "  # plt.scatter(x3_new, y_new)\n",
        "  # plt.scatter(x3, y3, color='r')\n",
        "  # plt.legend(['Model', 'Data'])\n",
        "  # plt.xlim(-2, 2)\n",
        "  # plt.ylim(-15, 15)\n",
        "  # plt.title(f\"Ridge regression n = 4 con 3 punti (alpha = {alpha_i})\")"
      ],
      "metadata": {
        "id": "-RxCHyORVPfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Regolarizzazione per problemi 1D\n",
        "\n",
        "### 2.1 Deblurring\n",
        "\n",
        "Passiamo ad esaminare segnali uni-dimensionali. A tal fine carichiamo la traccia di batteria che abbiamo gia incontrato nella prima lezione e selezioniamo un chunk di 300 sample."
      ],
      "metadata": {
        "id": "tnEzt9GxhnIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sr = 44100\n",
        "# carichiamo 300 samples a partire da 0:10\n",
        "t = 10\n",
        "n = 300\n",
        "drums, _ = librosa.load('drums.wav', sr=sr)\n",
        "drums_chunk = drums[t * sr: t * sr + n][:, np.newaxis]"
      ],
      "metadata": {
        "id": "rAjNJYUzhfTl"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizziamo il segnale:"
      ],
      "metadata": {
        "id": "EtLdNOP_nquc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_plot = drums_chunk\n",
        "x_plot = np.arange(y_plot.shape[0])\n",
        "plot(x_plot, y_plot, title=\"Segnale originale\")"
      ],
      "metadata": {
        "id": "1PF18n6PjO1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possiamo sfocare la traccia applicando un *kernel Gaussiano* locale $K \\in \\mathbb{R}^{n\\times n}$, tale che $K_{i, j} = g_{a,c}(j - i)$, dove $$g_{a,c}(j - i) = a \\exp{-\\frac{(j - i)^2}{2c^2}}.$$ Quando applichiamo un kernel Gaussiano a un segnale, stiamo effettivamente eseguendo una sorta di media ponderata locale dei valori del segnale. I valori del segnale vicino al centro del kernel hanno un peso maggiore nella media, mentre i valori più lontani dal centro hanno un peso minore.\n",
        "\n",
        "È facile verificare che ogni diagonale di questa matrice contiene termini costanti. Una matrice che soddisfa questa proprietà è detta *matrice di Toeplitz*."
      ],
      "metadata": {
        "id": "uZ6HsqGSoDZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_interval = np.arange(-n//2, n//2)\n",
        "\n",
        "a = 1.\n",
        "c = 4.\n",
        "kernel_row = a*np.exp(-kernel_interval**2/(2*c**2))\n",
        "\n",
        "y_plot = kernel_row\n",
        "x_plot = kernel_interval\n",
        "plot(x_plot, y_plot, title=\"Riga kernel Gaussiano (a = 1, c = 4)\")"
      ],
      "metadata": {
        "id": "zJSSRkw_iWgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_row_shifted = np.roll(kernel_row, shift=-n//2)\n",
        "y_plot = kernel_row_shifted\n",
        "x_plot = kernel_interval\n",
        "plot(x_plot, y_plot, title=\"Riga kernel Gaussiano shiftata (a = 1, c = 4)\")"
      ],
      "metadata": {
        "id": "pB6PZpZo1gwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = scipy.linalg.toeplitz(kernel_row_shifted)\n",
        "plt.imshow(K)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "RC65SBul55BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possiamo sfocare il segnale semplicemente applicando la matrice $K$:"
      ],
      "metadata": {
        "id": "uZAJk1dOuoqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drums_chunk_blur_c1 = K @ drums_chunk"
      ],
      "metadata": {
        "id": "9leuFGUyisqw"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_plot = drums_chunk_blur_c1\n",
        "x_plot = np.arange(y_plot.shape[0])\n",
        "plot(x_plot, y_plot, title=\"Segnale sfocato ($a=1, c=4$)\")\n",
        "\n",
        "\n",
        "y_plot = drums_chunk\n",
        "x_plot = np.arange(y_plot.shape[0])\n",
        "plot(x_plot, y_plot, title=\"Segnale originale\")"
      ],
      "metadata": {
        "id": "ZFhJIp82l-Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Osserviamo che il segnale è diventato più *smooth*. Vediamo cosa succede se aumentiamo il parametro $c$:"
      ],
      "metadata": {
        "id": "XOqpuZSIvDwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 1.\n",
        "c = 8.                                                            \n",
        "kernel_row = a*np.exp(-kernel_interval**2/(2*c**2))\n",
        "                                                                   \n",
        "y_plot = kernel_row                                                \n",
        "x_plot = kernel_interval                                           \n",
        "plot(x_plot, y_plot, title=\"Kernel Gaussiano (a = 1, c = 8)\")    \n",
        "\n",
        "kernel_row_shifted = np.roll(kernel_row, shift=-n//2)\n",
        "y_plot = kernel_row_shifted\n",
        "x_plot = kernel_interval\n",
        "plot(x_plot, y_plot, title=\"Kernel Gaussiano shiftato (a = 1, c = 8)\")\n",
        "\n",
        "K = scipy.linalg.toeplitz(kernel_row_shifted)\n",
        "plt.imshow(K)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "BQ3oDSe4mut1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drums_chunk_blur_c2 = K@drums_chunk"
      ],
      "metadata": {
        "id": "1lQo3DGjvJ7H"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_plot = drums_chunk_blur_c2\n",
        "x_plot = np.arange(y_plot.shape[0])\n",
        "plot(x_plot, y_plot, title=\"Segnale sfocato ($a=1, c=8$)\")"
      ],
      "metadata": {
        "id": "FHv7B8LMwjOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ci poniamo il seguente problema inverso: conoscendo la traccia sfocata $x_{\\text{blurry}}$ e l'operatore di blurring $G = K$, possiamo risalire alla traccia originale $x$? Il problema è sotto-determinato essendoci infinite $x$ tali che $G x = x_{\\text{blurry}}$. A tal fine risolviamo il problema usando un regolarizzatore di Tikhonov, provando diversi valori di $\\alpha$"
      ],
      "metadata": {
        "id": "eRJqaJAZywrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_blurry = drums_chunk_blur_c2\n",
        "\n",
        "alpha = 0.01\n",
        "\n",
        "x_1 = np.linalg.inv(K.T@K + alpha*np.eye(K.shape[1]))@K.T@x_blurry"
      ],
      "metadata": {
        "id": "yccwVzchy_BS"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_plot = x_1\n",
        "x_plot = np.arange(y_plot.shape[0])\n",
        "plot(x_plot, y_plot, title=\"Segnale ricostruito ($a=1$, $c=8$, $\\\\alpha = 0.01$)\")\n",
        "\n",
        "y_plot = drums_chunk_blur_c1\n",
        "x_plot = np.arange(y_plot.shape[0])\n",
        "plot(x_plot, y_plot, title=\"Segnale sfocato ($a=1, c=4$)\")\n",
        "\n",
        "y_plot = drums_chunk\n",
        "x_plot = np.arange(y_plot.shape[0])\n",
        "plot(x_plot, y_plot, title=\"Segnale originale\")"
      ],
      "metadata": {
        "id": "-i7DkJ1I4D3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non siamo riusciti a ricostruire fedelmente i dettagli, ma confrontando la soluzione con il segnale affetto da blur con $c=4$, notiamo che ci siamo avvicinati al segnale originale. Per avere una ricostruzione fedele si possono introdurre tecniche di learning (che esulano dallo scope di questa lezione).\n",
        "\n",
        "L'esempio precedente non può essere ascoltato. Questo perchè codifichiamo solamente 300/44100 = 0.006s di traccia, una quantità impercettibile all'udito. \n",
        "\n",
        "Ripetiamo l'esempio con 2 secondi di traccia ($n$ = 88200)"
      ],
      "metadata": {
        "id": "yPJx1zzl-x-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carichiamo 88200 samples a partire da 0:10\n",
        "n = 88200\n",
        "drums_long = drums[t * sr: t * sr + n][:, np.newaxis]\n",
        "\n",
        "IPython.display.Audio(drums_long[:, 0], rate=sr)"
      ],
      "metadata": {
        "id": "ui5ipOdpAR2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se proviamo a creare la matrice 𝐾 come prima ci imbattiamo in problemi di memoria (se provate a farlo il kernel Jupyter viene restartato avendo saturato la memoria). \n",
        "\n",
        "Nei casi in cui la maggior parte delle entrate di una matrice sono zeri, conviene usare matrici sparse. Le matrici sparse memorizzano solamente le entrate diverse da zero, e quindi è possibile rappresentare dati alto-dimensionali senza imbatersi in problemi di memoria. Dato che il kernel Gaussiano tende esponenzialmente a zero allontanandosi dalla media, le matrici di blurring in effetti possono essere rappresentate come matrici sparse."
      ],
      "metadata": {
        "id": "GO3ZPXScCedu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scegliamo un numero di diagonali non nulle nella matrice sparse (in questo caso 40).\n",
        "nonzero_entries = 40\n",
        "\n",
        "\n",
        "kernel_interval = np.arange(-nonzero_entries//2, nonzero_entries//2, dtype=np.int64) #entries, dtype=np.int64) - (entries//2)\n",
        "\n",
        "a = 1.\n",
        "c = 8.\n",
        "kernel_row = a*np.exp(-kernel_interval**2/(2*c**2))\n",
        "K = sparse.diags(kernel_row, kernel_interval, shape=(n, n)) \n",
        "\n",
        "print(f\"K = {repr(K)}\")"
      ],
      "metadata": {
        "id": "LGRkRB3k9cfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se usassimo una matrice densa, $K$ peserebbe 88200 $\\times$ 88200 $\\times$ 8 bytes = 62 Gb 🤡. Dato che usiamo solo 3527600 elementi, quest'ultima pesa solamente 3 Mb, ~1764 volte di meno!\n",
        "\n",
        "Smoothiamo il segnale con $K$:"
      ],
      "metadata": {
        "id": "oRkTjH3ZIFH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drums_long_blur = K @ drums_long\n",
        "\n",
        "IPython.display.Audio(drums_long_blur[:, 0], rate=sr)"
      ],
      "metadata": {
        "id": "PDZkxXQOJ69p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per effettuare i minimi quadrati con matrici sparse, non possiamo procedere come nel caso denso. Esistono metodi iterativi (metodi che vedremo più approfonditamente nelle prossime lezioni) per minimi quadrati su matrici sparse. Usiamo il metodo *LSMR* (https://arxiv.org/abs/1006.0758) implementato in `scipy`. Il valore $\\alpha$ della regolarizzazione di Tikhonov può essere impostato nel parametro `damp`:"
      ],
      "metadata": {
        "id": "z7S4KaSdKuc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = scipy.sparse.linalg.lsmr(K, drums_long_blur, damp=0.01)[0]\n",
        "IPython.display.Audio(x, rate=sr)"
      ],
      "metadata": {
        "id": "F48tU2hMLRJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Denoising\n",
        "\n",
        "Possiamo affrontare il problema ortogonale al deblurring, ossia il denoising. Supponiamo che il nostro segnale $\\mathbf{x}$ sia stato corrotto con del rumore Gaussiano $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2\\mathbf{I})$ ($\\sigma$ ha un ruolo simile alla $c$ vista nell'esempio di deblurring, in effetti se la funzione Gaussiana dell'esempio precedente e' tale che il suo integrale su tutto $\\mathbb{R}$ è 1 allora  $\\sigma = c$; da notare che in questo caso abbiamo una Gaussiana multivariata): $$\\mathbf{x}_{\\text{noisy}} = \\mathbf{x} + \\mathbf{z}.$$ Il nostro task adesso è quello di ottenere una soluzione più smooth, rimuovendo il rumore. A tal fine vogliamo risolvere il seguente problema di minimizzazione:\n",
        "$$ \\mathbf{x}_{\\text{smooth}} = \\operatorname*{arg\\,min}_\\mathbf{x} \\Vert \\mathbf{x} - \\mathbf{x}_{\\text{noisy}}\\Vert^2_2 + \\alpha \\Vert D \\mathbf{x}\\Vert^2_2 $$ dove $D$ è la derivata discreta: $$ D = \\begin{bmatrix} 1 & -1 & \\dots & 0 \\\\ 0 & 1 & \\dots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & 1 \\end{bmatrix}.$$ Anche in questo caso la matrice $D$ è di Toepliz.\n"
      ],
      "metadata": {
        "id": "CrED-wxlin_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Esercizio 2\n",
        "1. Scrivere l'equazione normale per il problema di minimizzazione definito sopra.\n",
        "2. Perturbare `drums_chunk` con rumore Gaussiano bianco per ottenere `x_noisy`. Clippare nell'intervallo -1 e 1.\n",
        "3. Risolvere il problema dei minimi quadrati regolarizzato per trovare la soluzione e plottare la soluzione.\n",
        "4. Perturbare tutto `drums_long`, ottenendo `drums_long_noisy` poi ascoltare la versione noisy. \n",
        "5. Risolvere il problema su `drums_long` applicando iterativamente il metodo su chunk locali. Ascoltare il risultato.\n"
      ],
      "metadata": {
        "id": "5jOo1uPaoY6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 300\n",
        "sigma = 0.05\n",
        "alpha = 100.\n",
        "drums_small_chunk = drums_long[:n]\n",
        "from scipy.linalg import toeplitz\n",
        "\n",
        "# SCRIVERE QUI SOTTO IL CODICE DELL'ESERCIZIO\n",
        "################\n",
        "\n",
        "\n",
        "# Perturbiamo drums_small_chunk con rumore Gaussiano\n",
        "# Campioniamo una z (usare np.random.randn e moltiplicare per sigma**2)\n",
        "\n",
        "noise = ...\n",
        "x_noisy = ...\n",
        "# x_noisy = np.clip(x_noisy , -1, 1)\n",
        "\n",
        "\n",
        "# Risolviamo per la x (usare np.diags poi convertire a np.ndarray)\n",
        "\n",
        "# D = sparse.diags(...).toarray()\n",
        "x_smooth = ...\n",
        "\n",
        "# plt.figure()\n",
        "# y_plot = ...\n",
        "# x_plot = np.arange(y_plot.shape[0])\n",
        "# plot(x_plot, y_plot, title=\"Segnale noisy ($\\\\sigma = 0.05$)\")\n",
        "\n",
        "# plt.figure()\n",
        "# y_plot = ...\n",
        "# x_plot = np.arange(y_plot.shape[0])\n",
        "# plot(x_plot, y_plot, title=\"Segnale originale\")\n",
        "\n",
        "# plt.figure()\n",
        "# y_plot = ...\n",
        "# x_plot = np.arange(y_plot.shape[0])\n",
        "# plot(x_plot, y_plot, title=\"Segnale ricostruito ($\\\\alpha = 100, \\\\sigma = 0.05$)\")"
      ],
      "metadata": {
        "id": "8p52PXGopzb0"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Risolviamo su drums_long\n",
        "\n",
        "noise_long = ...\n",
        "# drums_long_noisy = np.clip(..., -1, 1)\n",
        "\n",
        "# IPython.display.Audio(drums_long_noisy[:, 0], rate=sr)"
      ],
      "metadata": {
        "id": "5yXmP52Y4j9_"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# smoothed_drums_long = np.zeros_like(drums_long_noisy)\n",
        "\n",
        "# for i in range(88200 // n):\n",
        "#   x_noisy_chunk = ...\n",
        "#   x_smooth_chunk = ...\n",
        "#   smoothed_drums_long[i*chunk_size:(i+1)*chunk_size] = x_smooth_chunk\n",
        "\n",
        "# IPython.display.Audio(smoothed_drums_long[:, 0], rate=sr)"
      ],
      "metadata": {
        "id": "7CvlhD_G4oKr"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Regolarizzazione per problemi 2D\n",
        "\n",
        "Passiamo a problemi di regolarizzazione nel setting 2D. A tal proposito, ripetiamo l'esercizio precedente nel setting 2D.\n",
        "\n",
        "## Esercizio 3\n",
        "1. Caricare l'immagine `mountain.jpg` usando PIL\n",
        "2. Perturbare l'immagine con rumore Gaussiano bianco per ottenere `x_noisy`\n",
        "3. Risolvere il problema di denoising applicando iterativamente il metodo dei minimi quadrati prima sulle righe poi sulle colonne. Visualizzare il risultato."
      ],
      "metadata": {
        "id": "DIIwdIKIEaSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = 0.5\n",
        "alpha = 6.\n",
        "n = 256 \n",
        "chunk_size = 32\n",
        "\n",
        "# SCRIVERE QUI SOTTO IL CODICE DELL'ESERCIZIO\n",
        "################\n",
        "\n",
        "\n",
        "# carichiamo l'imagine con PIL\n",
        "image = Image.open('mountain.png')\n",
        "# trasformiamo in un vettore np dopo aver normalizzato\n",
        "pix = np.array(image) / np.max(np.array(image))\n",
        "\n",
        "# plottiamo l'immagine\n",
        "plt.imshow(pix)\n",
        "\n",
        "# creare rumore e aggiungere al dato\n",
        "noise = ...\n",
        "x_noisy = ...\n",
        "# x_noisy = np.clip(x_noisy, 0., 1.)\n",
        "\n",
        "# plottiamo l'immagine noisy\n",
        "# plt.imshow(x_noisy)\n",
        "# plt.show()\n",
        "\n",
        "# kernel di derivazione \n",
        "def denoise(signal, alpha):\n",
        "    # D = sparse.diags(...).toarray()\n",
        "    x_smooth = ...\n",
        "    return x_smooth\n",
        "    \n",
        "# iteriamo su ogni riga e canale\n",
        "# denoised_image = np.zeros_like(x_noisy)\n",
        "# for i in ...:\n",
        "#   for c in range(...):\n",
        "#     denoised_image[i, :, c] = ...\n",
        "\n",
        "# plt.imshow(denoised_image)\n",
        "# plt.show()\n",
        "\n",
        "# iteriamo su ogni colonna\n",
        "# denoised_image_2d = np.zeros_like(denoised_image)\n",
        "# for i in ...:\n",
        "#   for c in ...:\n",
        "#    denoised_image_2d[:, i, c] = ...\n",
        "\n",
        "# plt.imshow(denoised_image_2d)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "dWJxoUJcF8ZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}